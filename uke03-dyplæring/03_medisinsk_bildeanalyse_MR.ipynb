{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Medisinsk Bildeanalyse med MR og PyTorch\n",
    "\n",
    "I denne notebook-en skal vi bygge en dyplæringsmodell for å analysere medisinske bilder. Vi går bort fra røntgenbildene vi så på tidligere, og fokuserer nå på **magnetisk resonanstomografi (MR)**-bilder av hjernen.\n",
    "\n",
    "**Mål:** Vi skal trene et **Convolutional Neural Network (CNN)** til å klassifisere MR-bilder og skille mellom hjerner fra friske kontrollpersoner og personer med demens.\n",
    "\n",
    "**Datasett:** Vi bruker et lite utvalg fra [OASIS-1](https://www.oasis-brains.org/)-datasettet. Dataene består av 3D MR-bilder i NIfTI-format (`.nii`). For å gjøre oppgaven enklere, vil vi trekke ut ett 2D-snitt fra midten av hver 3D-skanning for å utføre 2D-bildeklassifisering.\n",
    "\n",
    "**Verktøy:**\n",
    "- **PyTorch:** Et populært rammeverk for dyp læring.\n",
    "- **Nibabel:** Et Python-bibliotek for å lese og skrive vanlige medisinske bildeformater, som NIfTI.\n",
    "- **Scikit-learn:** For datasplitting og evaluering.\n",
    "- **Matplotlib:** For visualisering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steg 1: Importere Nødvendige Biblioteker\n",
    "\n",
    "Først importerer vi alle bibliotekene vi trenger for databehandling, modellbygging, trening og evaluering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bruker enhet: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Sjekk om GPU eller MPS er tilgjengelig og sett enhet (device)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'Bruker enhet: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0\n",
      "MPS tilgjengelig: True\n",
      "MPS bygget: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"MPS tilgjengelig: {torch.backends.mps.is_available()}\")\n",
    "print(f\"MPS bygget: {torch.backends.mps.is_built()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steg 2: Laste inn og Utforske Dataene\n",
    "\n",
    "Vi antar at dataene er organisert i en mappestruktur som dette:\n",
    "```\n",
    "data/\n",
    "└── oasis_mri_sample/\n",
    "    ├── demented/\n",
    "    │   └── subject_1.nii\n",
    "    └── nondemented/\n",
    "        └── subject_2.nii\n",
    "```\n",
    "\n",
    "Vi lager en funksjon som leser alle `.nii`-filene, trekker ut det midterste 2D-snittet fra 3D-volumet, og lagrer bildene sammen med sine etiketter (0 for `nondemented`, 1 for `demented`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En robust og standardisert metode: å laste ned dataene direkte fra Kaggle ved hjelp av deres API.\n",
    "Dette er standard, garantert å fungere, og en veldig nyttig ferdighet å kunne. Det krever et lite, engangs-oppsett fra din side, men da vil du ha en stabil løsning.\n",
    "\n",
    "#### Steg 1: Skaff din Kaggle API-nøkkel (tar 30 sekunder)\n",
    "\n",
    "- Logg inn på din Kaggle-konto (eller opprett en gratis).\n",
    "- Gå til din kontoside ved å klikke på profilikonet ditt og velge \"Account\".\n",
    "- Scroll ned til seksjonen som heter \"API\".\n",
    "- Klikk på knappen \"Create New API Token\".\n",
    "- Dette vil laste ned en fil som heter kaggle.json. Ta vare på denne filen.\n",
    "\n",
    "#### Steg 2: Oppdatert Python-skript\n",
    "\n",
    "Nå skal vi bruke kaggle.json-filen i koden. Når du kjører skriptet under, må kaggle.json ligge i samme mappe, eller du må laste den opp til din Jupyter/Colab-økt.\n",
    "\n",
    "Dette skriptet vil:\n",
    "- Installere Kaggle-biblioteket.\n",
    "- Sette opp API-tilgangen ved hjelp av din kaggle.json-fil.\n",
    "- Laste ned det korrekte datasettet.\n",
    "- Reorganisere filene slik din notebook forventer dem.\n",
    "\n",
    "Hvordan du bruker den nye koden:\n",
    "\n",
    "- Få kaggle.json som beskrevet i Steg 1.\n",
    "- Plasser kaggle.json i samme mappe som du kjører Python-skriptet fra.\n",
    "- Kjør skriptet. Det vil nå autentisere seg mot Kaggle og laste ned dataene på en stabil og sikker måte.\n",
    "\n",
    "Denne metoden er standarden i feltet og vil garantert fungere så lenge Kaggle-datasettet er tilgjengelig. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "def setup_kaggle_api():\n",
    "    \"\"\"\n",
    "    Sets up the Kaggle API credentials from kaggle.json.\n",
    "    \"\"\"\n",
    "    if not os.path.exists('kaggle.json'):\n",
    "        print(\"Feil: `kaggle.json` ble ikke funnet.\")\n",
    "        print(\"Vennligst følg steg 1 i instruksjonene for å laste ned filen,\")\n",
    "        print(\"og plasser den i samme mappe som dette skriptet.\")\n",
    "        return False\n",
    "        \n",
    "    print(\"Setter opp Kaggle API-nøkkel...\")\n",
    "    # Create the .kaggle directory\n",
    "    kaggle_dir = os.path.expanduser('~/.kaggle')\n",
    "    os.makedirs(kaggle_dir, exist_ok=True)\n",
    "    \n",
    "    # Move the file and set permissions\n",
    "    shutil.copy('kaggle.json', os.path.join(kaggle_dir, 'kaggle.json'))\n",
    "    os.chmod(os.path.join(kaggle_dir, 'kaggle.json'), 0o600)\n",
    "    \n",
    "    # Import kaggle library after setup\n",
    "    try:\n",
    "        global kaggle\n",
    "        import kaggle\n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(\"Kaggle-biblioteket er ikke installert. Prøver å installere...\")\n",
    "        subprocess.run([\"pip\", \"install\", \"-q\", \"kaggle\"])\n",
    "        import kaggle\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"En feil oppstod under import av kaggle: {e}\")\n",
    "        return Fals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_setup_mri_data():\n",
    "    \"\"\"\n",
    "    Downloads, extracts, and reorganizes MRI data from Kaggle for\n",
    "    binary classification (demented vs. nondemented).\n",
    "    \"\"\"\n",
    "    if not setup_kaggle_api():\n",
    "        return\n",
    "\n",
    "    # --- Configuration ---\n",
    "    base_dir = './data/oasis_mri_sample'\n",
    "    temp_extract_folder = os.path.join(base_dir, 'temp_extracted')\n",
    "    dataset_id = 'tourist55/alzheimers-dataset-4-class-of-images'\n",
    "    zip_file_name = 'alzheimers-dataset-4-class-of-images.zip'\n",
    "\n",
    "    # Create base directory\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"\\nLaster ned datasettet '{dataset_id}' fra Kaggle...\")\n",
    "    \n",
    "    try:\n",
    "        # Download the dataset\n",
    "        kaggle.api.dataset_download_files(dataset_id, path=base_dir, unzip=False, quiet=False)\n",
    "\n",
    "        # Unzip the file\n",
    "        zip_path = os.path.join(base_dir, zip_file_name)\n",
    "        print(f\"\\nPakker ut '{zip_file_name}'...\")\n",
    "        with kaggle.api.zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(temp_extract_folder)\n",
    "\n",
    "        print(\"Reorganiserer filene til 'demented' og 'nondemented'...\")\n",
    "        \n",
    "        # --- Reorganization Logic ---\n",
    "        demented_dest = os.path.join(base_dir, 'demented')\n",
    "        nondemented_dest = os.path.join(base_dir, 'nondemented')\n",
    "        os.makedirs(demented_dest, exist_ok=True)\n",
    "        os.makedirs(nondemented_dest, exist_ok=True)\n",
    "        \n",
    "        # The source has an extra 'Alzheimer_s Dataset' folder\n",
    "        source_root = os.path.join(temp_extract_folder, 'Alzheimer_s Dataset')\n",
    "        \n",
    "        # Copy 'NonDemented' files from the 'train' folder\n",
    "        nondemented_src = os.path.join(source_root, 'train', 'NonDemented')\n",
    "        for filename in tqdm(os.listdir(nondemented_src), desc=\"Kopierer NonDemented\"):\n",
    "            shutil.copy(os.path.join(nondemented_src, filename), nondemented_dest)\n",
    "            \n",
    "        # Combine all 'Demented' categories from the 'train' folder\n",
    "        demented_categories = ['VeryMildDemented', 'MildDemented', 'ModerateDemented']\n",
    "        for category in demented_categories:\n",
    "            category_src = os.path.join(source_root, 'train', category)\n",
    "            for filename in tqdm(os.listdir(category_src), desc=f\"Kopierer {category}\"):\n",
    "                shutil.copy(os.path.join(category_src, filename), demented_dest)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"En feil oppstod: {e}\")\n",
    "        print(\"Sjekk at du har skrevet inn riktig datasett-ID og at `kaggle.json` er gyldig.\")\n",
    "    finally:\n",
    "        # --- Cleanup ---\n",
    "        print(\"\\nRydder opp midlertidige filer...\")\n",
    "        zip_path = os.path.join(base_dir, zip_file_name)\n",
    "        if os.path.exists(zip_path):\n",
    "            os.remove(zip_path)\n",
    "        if os.path.exists(temp_extract_folder):\n",
    "            shutil.rmtree(temp_extract_folder)\n",
    "\n",
    "    # --- Verification ---\n",
    "    try:\n",
    "        demented_count = len(os.listdir(demented_dest))\n",
    "        nondemented_count = len(os.listdir(nondemented_dest))\n",
    "        \n",
    "        print(f\"\\nOppsett fullført! Data er organisert:\")\n",
    "        print(f\"- {demented_count} bilder i mappen 'demented'\")\n",
    "        print(f\"- {nondemented_count} bilder i mappen 'nondemented'\")\n",
    "    except NameError:\n",
    "         print(\"\\nReorganisering ble ikke fullført på grunn av en tidligere feil.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\nKunne ikke telle filer. Noe gikk galt under reorganiseringen.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laster ned MRI-data fra ny kilde...\n",
      "Feil under nedlasting: 404 Client Error: Not Found for url: https://github.com/Mina-Karam/Alzheimer-s-MRI-Predection/raw/main/Dataset.zip\n",
      "Rydder opp midlertidige filer...\n"
     ]
    }
   ],
   "source": [
    "# Eksempel på hvordan funksjonen kjøres\n",
    "\n",
    "# Vi sjekker om data allrede eksiterer for å unngå ny nedlastning\n",
    "data_dir_check = './data/oasis_mri_sample/demented'\n",
    "if not os.path.exists(data_dir_check) or not os.listdir(data_dir_check):\n",
    "    download_and_setup_mri_data()\n",
    "else:\n",
    "    print(\"Data ser ut til å allerede eksistere. Hopper over nedlasting.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingen bilder ble lastet inn. Sjekk stien til dataene og mappestrukturen.\n"
     ]
    }
   ],
   "source": [
    "def load_mri_data(data_path):\n",
    "    \"\"\"Laster inn MR-data og returnerer 2D-snitt og etiketter.\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for label, category in enumerate(['nondemented', 'demented']):\n",
    "        category_path = os.path.join(data_path, category)\n",
    "        if not os.path.isdir(category_path):\n",
    "            print(f\"Advarsel: Mappen {category_path} ble ikke funnet.\")\n",
    "            continue\n",
    "            \n",
    "        for filename in os.listdir(category_path):\n",
    "            if filename.endswith('.nii'):\n",
    "                img_path = os.path.join(category_path, filename)\n",
    "                try:\n",
    "                    # Last inn NIfTI-filen\n",
    "                    nii_img = nib.load(img_path)\n",
    "                    img_data = nii_img.get_fdata()\n",
    "                    \n",
    "                    # Hent ut det midterste snittet langs z-aksen\n",
    "                    mid_slice_idx = img_data.shape[2] // 2\n",
    "                    mid_slice = img_data[:, :, mid_slice_idx]\n",
    "                    \n",
    "                    # Roter bildet for riktig visning\n",
    "                    mid_slice = np.rot90(mid_slice)\n",
    "                    \n",
    "                    images.append(mid_slice)\n",
    "                    labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Kunne ikke laste {img_path}: {e}\")\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Angi stien til dataene (endre denne om nødvendig)\n",
    "DATA_DIR = '../../data/oasis_mri_sample/' # Antar at dataene ligger i en mappe på samme nivå som `uke03`\n",
    "\n",
    "# Opprett datamapper hvis de ikke eksisterer\n",
    "os.makedirs(os.path.join(DATA_DIR, 'nondemented'), exist_ok=True)\n",
    "os.makedirs(os.path.join(DATA_DIR, 'demented'), exist_ok=True)\n",
    "\n",
    "images, labels = load_mri_data(DATA_DIR)\n",
    "\n",
    "if len(images) > 0:\n",
    "    print(f'Lastet inn {len(images)} bilder.')\n",
    "    print(f'Bildedimensjoner: {images[0].shape}')\n",
    "    print(f'Antall i hver klasse: {np.bincount(labels)}')\n",
    "else:\n",
    "    print('Ingen bilder ble lastet inn. Sjekk stien til dataene og mappestrukturen.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisere Eksempelbilder\n",
    "\n",
    "Det er alltid lurt å se på dataene for å få en intuisjon for hva modellen skal lære. Vi viser ett eksempel fra hver klasse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(images) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    # Finn første bilde av en frisk person\n",
    "    nondemented_idx = np.where(labels == 0)[0][0]\n",
    "    axes[0].imshow(images[nondemented_idx], cmap='gray')\n",
    "    axes[0].set_title('Klasse: Nondemented (Frisk)')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Finn første bilde av en dement person\n",
    "    demented_idx = np.where(labels == 1)[0][0]\n",
    "    axes[1].imshow(images[demented_idx], cmap='gray')\n",
    "    axes[1].set_title('Klasse: Demented (Demens)')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steg 3: Forprosessering og Klargjøring av Data\n",
    "\n",
    "For at et nevralt nettverk skal kunne behandle bildene, må vi:\n",
    "1.  **Dele dataene** inn i et treningssett og et valideringssett.\n",
    "2.  **Opprette en egendefinert `Dataset`-klasse** i PyTorch. Dette er standard praksis for å håndtere data effektivt.\n",
    "3.  **Definere transformasjoner:** Bildene må konverteres til PyTorch-tensorer, få endret størrelse til en fast dimensjon (f.eks. 128x128), og normaliseres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Del dataene i trenings- og valideringssett\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f'Størrelse på treningssett: {len(X_train)}')\n",
    "print(f'Størrelse på valideringssett: {len(X_val)}')\n",
    "\n",
    "# 2. Lag en egendefinert Dataset-klasse\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Legg til en kanal-dimensjon (for gråtonebilder)\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# 3. Definer transformasjoner\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128, 128)),\n",
    "    # Normalisering med gjennomsnitt og standardavvik for datasettet\n",
    "    # For enkelhets skyld bruker vi (0.5, 0.5) som er vanlig for bilder i [-1, 1] området\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Opprett Dataset- og DataLoader-objekter\n",
    "train_dataset = MRIDataset(X_train, y_train, transform=data_transforms)\n",
    "val_dataset = MRIDataset(X_val, y_val, transform=data_transforms)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steg 4: Bygge CNN-Modellen\n",
    "\n",
    "Nå definerer vi arkitekturen til vårt nevrale nettverk. Vi lager en enkel CNN-modell med to konvolusjonslag etterfulgt av to fullt-tilkoblede (dense) lag.\n",
    "\n",
    "**Arkitektur:**\n",
    "1.  `Conv2d` -> `ReLU` -> `MaxPool2d` (Første konvolusjonsblokk)\n",
    "2.  `Conv2d` -> `ReLU` -> `MaxPool2d` (Andre konvolusjonsblokk)\n",
    "3.  `Flatten` (Gjør om 2D-kart til 1D-vektor)\n",
    "4.  `Linear` -> `ReLU` (Første tette lag)\n",
    "5.  `Linear` (Output-lag, som gir en score for hver klasse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        # Etter to pooling-lag vil et 128x128 bilde bli 32x32\n",
    "        # Størrelsen på input til det lineære laget er 32 * 32 * 32 (kanaler)\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 32 * 32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2) # 2 klasser: nondemented og demented\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n",
    "\n",
    "# Initialiser modellen og flytt den til GPU hvis tilgjengelig\n",
    "model = SimpleCNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steg 5: Trene Modellen\n",
    "\n",
    "Nå er vi klare til å trene modellen. Vi må definere:\n",
    "- **En tapsfunksjon (Loss Function):** Måler hvor feil modellen predikerer. `CrossEntropyLoss` er standard for klassifiseringsoppgaver.\n",
    "- **En optimaliseringsalgoritme (Optimizer):** Oppdaterer vektene i nettverket for å minimere tapet. `Adam` er et robust og populært valg.\n",
    "\n",
    "Deretter skriver vi en treningsløkke som itererer over dataene i et visst antall *epochs*. For hver epoch trener vi på treningssettet og evaluerer på valideringssettet for å overvåke ytelsen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definer hyperparametere\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 20\n",
    "\n",
    "# Definer tapsfunksjon og optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # --- Treningsfase ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Nullstill gradienter\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass og optimalisering\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_acc = correct_train / total_train\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "\n",
    "    # --- Valideringsfase ---\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad(): # Ingen grunn til å beregne gradienter her\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = running_loss / len(val_loader.dataset)\n",
    "    val_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS} | ' \\\n",
    "          f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | ' \\\n",
    "          f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steg 6: Evaluere Modellen\n",
    "\n",
    "Etter treningen er det viktig å evaluere modellens ytelse. Vi gjør dette på flere måter:\n",
    "1.  **Plotte treningshistorikk:** Vi ser på hvordan tap og nøyaktighet utvikler seg over tid for både trenings- og valideringssettet. Dette kan avsløre problemer som *overfitting*.\n",
    "2.  **Forvirringsmatrise (Confusion Matrix):** Viser en tabell over hvor mange bilder som ble korrekt og feilaktig klassifisert for hver klasse. Dette gir et mer detaljert bilde enn bare nøyaktighet.\n",
    "3.  **Klassifiseringsrapport:** Gir en oppsummering av presisjon, sensitivitet (recall) og F1-score for hver klasse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Plotte treningshistorikk\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.plot(history['train_loss'], label='Training Loss')\n",
    "ax1.plot(history['val_loss'], label='Validation Loss')\n",
    "ax1.set_title('Loss over Epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history['train_acc'], label='Training Accuracy')\n",
    "ax2.plot(history['val_acc'], label='Validation Accuracy')\n",
    "ax2.set_title('Accuracy over Epochs')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 & 3. Forvirringsmatrise og klassifiseringsrapport\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "class_names = ['Nondemented', 'Demented']\n",
    "print(\"Klassifiseringsrapport:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Forvirringsmatrise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konklusjon\n",
    "\n",
    "I denne notebook-en har vi bygget en ende-til-ende-løsning for klassifisering av MR-bilder ved hjelp av PyTorch.\n",
    "\n",
    "Vi har:\n",
    "1.  Lastet inn og forprosessert medisinske bilder i NIfTI-format.\n",
    "2.  Definert en egendefinert `Dataset`-klasse for å håndtere dataene i PyTorch.\n",
    "3.  Bygget og trent en enkel CNN-modell fra bunnen av.\n",
    "4.  Evaluert modellens ytelse med relevante metrikker som nøyaktighet, forvirringsmatrise og klassifiseringsrapport.\n",
    "\n",
    "Dette er et startpunkt. For å forbedre modellen kan man utforske:\n",
    "- **Dataaugmentering:** Roter, zoom eller flipp bildene for å kunstig øke størrelsen på treningssettet.\n",
    "- **Mer avanserte arkitekturer:** Bruk forhåndstrente modeller som ResNet (transfer learning).\n",
    "- **3D-konvolusjoner:** Utnytt den fulle 3D-informasjonen i MR-skanningene ved å bruke `Conv3d`-lag."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-helse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
